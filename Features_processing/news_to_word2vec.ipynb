{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca38389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "news = pd.read_csv('news_data.csv')\n",
    "news['date'] = pd.to_datetime(news['date'])\n",
    "\n",
    "group = news.groupby(['date'], as_index=False)\n",
    "\n",
    "# 取出每日熱度前十的新聞標題\n",
    "group.apply(lambda df: df.sort_values(by=['hot'], ascending = False).head(10)).to_csv('sort.csv',encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1decc642",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort = pd.read_csv('sort.csv')\n",
    "dictkeys = sort['date'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c67ae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用結巴條件將新聞標題進行斷詞\n",
    "import jieba\n",
    "\n",
    "# load stopwords set\n",
    "stopword_set = set()\n",
    "with open('stopwords.txt','r', encoding='utf-8-sig') as stopwords:\n",
    "    for stopword in stopwords:\n",
    "        stopword_set.add(stopword.strip('\\n'))\n",
    "\n",
    "\n",
    "\n",
    "output = open('news_seg.txt', 'w', encoding='utf-8-sig')\n",
    "for sentence in sort['title'].values:\n",
    "    words = jieba.cut(sentence)\n",
    "    for word in words:\n",
    "        if word not in stopword_set:\n",
    "            output.write(word + ' ')\n",
    "    output.write('\\n')\n",
    "    #print('/'.join(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780d376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用Stanza套件取出重要詞性(名詞、動詞、形容詞)\n",
    "import stanza\n",
    "\n",
    "nlp = stanza.Pipeline(lang=\"zh\")\n",
    "news_seg_file = open('news_seg.txt','r', encoding='utf-8-sig')\n",
    "word2vec_training_file = open('word2vec_training.txt', 'w', encoding='utf-8-sig')\n",
    "\n",
    "for sentence in news_seg_file:\n",
    "\n",
    "    # 詞性標記\n",
    "    doc = nlp(sentence)\n",
    "\n",
    "    for sentence in doc.sentences:\n",
    "        for word in sentence.words:\n",
    "            if word.pos == \"NOUN\" or word.pos == \"VERB\" or word.pos == \"ADJ\":\n",
    "                word2vec_training_file.write(word.text + ' ')\n",
    "            \n",
    "    word2vec_training_file.write('\\n')      \n",
    "    \n",
    "word2vec_training_file.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3743f1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 產生word2vec詞向量轉換結果\n",
    "from gensim.models import word2vec\n",
    "sentences = word2vec.LineSentence(\"word2vec_training.txt\")\n",
    "model = word2vec.Word2Vec(sentences, vector_size=100)\n",
    "model.save(\"word2vec.model\")\n",
    "model = word2vec.Word2Vec.load(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47ecdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = pd.read_csv('word2vec_training_2.txt', delimiter = \"\\t\", header = None)\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dee86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = pd.concat([sort, txt], axis=1)\n",
    "finaldf['date'] = pd.to_datetime(finaldf['date'])\n",
    "finaldf = finaldf.groupby('date').sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5308d0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_split = finaldf[0].apply(lambda x: x.split())\n",
    "word_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885ca9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list = []\n",
    "for words in word_split:\n",
    "    temp_list = []\n",
    "    for word in words:\n",
    "        if word in model.wv.key_to_index:\n",
    "            temp_list.append(model.wv[word].tolist())\n",
    "    final_list.append(temp_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd12bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalword2vec = pd.DataFrame(final_list,index = dictkeys).fillna(0)\n",
    "finalword2vec.to_csv('word2vec.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
